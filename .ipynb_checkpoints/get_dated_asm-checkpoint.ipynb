{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/rx32940/Dropbox/5.Rachel-projects/Phylogeography/Dated_Assemblies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collected from ncbi SRA databases with keyword \"Leptospira\"\n",
    "all_data = pd.read_csv(path + \"Leptospira_sra_all_1258.csv\")\n",
    "\n",
    "wgs = all_data[(all_data[\"Assay Type\"] == \"WGS\") & \n",
    "               (all_data[\"Collection_Date\"].notnull()) & \n",
    "               (all_data[\"Collection_Date\"] != \"not applicable\") & \n",
    "              (all_data[\"Collection_Date\"] != \"missing\")]\n",
    "\n",
    "pd.unique(wgs[\"Collection_Date\"])\n",
    "\n",
    "wgs \n",
    "\n",
    "# wgs.to_csv(path + \"Leptospira_sra_datedWGS_248.csv\") \n",
    "\n",
    "# row 242 to 245, added geographic_location_(country_and/or_sea) info to geo_loc_name\n",
    "wgs = pd.read_csv(path + \"Leptospira_sra_datedWGS_248.csv\")\n",
    "\n",
    "wgs = wgs.drop([\"Alias\",\"Alias\",\"INSDC_status\",\"SRA_accession\",\"title\",\"geographic_location_(country_and/or_sea)\",\"env_biome\",\"env_feature\",\n",
    "               \"env_feature\",\"Depth\",\"project_name\",\"samp_collect_device\",\"sample_name\",\"INSDC_center_name\",\"env_material\",\n",
    "                \"host_scientific_name\", \"sample_ID\",\"host_subject_ID\",\"sample_comment\"], axis=1) # axis = 1 is column, axis = 0 is row\n",
    "# wgs.to_csv(path + \"Leptospira_sra_datedWGS_248.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collected from PATRIC database with keyword \"Leptospira\" -> Genomes (681)\n",
    "all_genomes = pd.read_csv(path + \"PATRIC_genome-681.csv\")\n",
    "all_genomes = all_genomes[((all_genomes[\"Genome Status\"] == \"WGS\") | (all_genomes[\"Genome Status\"] == \"Complete\")) &\n",
    "                         (all_genomes[\"Collection Date\"].notnull())]\n",
    "\n",
    "all_genomes = all_genomes.drop([\"Biovar\",\"Pathovar\",\"Other Typing\", \"Culture Collection\", \"Type Strain\", \"Completion Date\", \"Publication\",\n",
    "                               \"Assembly Accession\",\"RefSeq CDS\", \"Isolation Site\", 'Host Age', \"Host Gender\",\n",
    "                                'Host Health', 'Body Sample Site', 'Body Sample Subsite',\n",
    "                                'Other Clinical', 'AntiMicrobial Resistance',\n",
    "                                'AntiMicrobial Resistance Evidence', 'Gram Stain', 'Cell Shape',\n",
    "                                'Motility', 'Sporulation', 'Temperature Range', 'Optimal Temperature',\n",
    "                                'Salinity', 'Oxygen Requirement', 'Habitat', 'Disease','Date Inserted', 'Date Modified','PATRIC CDS','Latitude', 'Longitude',\n",
    "                                'Altitude', 'Depth', 'Other Environmental','Coarse Consistency', 'Fine Consistency',\n",
    "       'Checkm Completeness', 'Checkm Contamination','Chromosomes', 'Plasmids',\"Comments\",\"MLST\"], axis=1)\n",
    "\n",
    "# some genomes belongs to the phage of Leptospira\n",
    "all_genomes = all_genomes[(all_genomes[\"Genome Name\"].str.contains(\"phage\") == False) & (all_genomes[\"Genome Quality\"] == \"Good\")]\n",
    "all_genomes = all_genomes.rename(columns = {\"BioSample Accession\":\"BioSample\", \"BioProject Accession\" : \"BioProject\"})\n",
    "# all_genomes.to_csv(path + \"PATRIC_WGS_dated_353.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_biosamples = pd.merge(all_genomes, wgs, how= \"outer\")\n",
    "\n",
    "merged_biosample_acc = pd.DataFrame(pd.unique(merged_biosamples[\"BioSample\"]))\n",
    "merged_bioproject = pd.DataFrame(pd.unique(merged_biosamples[\"BioProject\"]))\n",
    "\n",
    "# merged_bioproject.to_csv(path + \"ncbi_patric_dated_110_biopoject.txt\", header=None, index=None,sep=\"\\n\")\n",
    "# merged_biosample_acc.to_csv(path + \"ncbi_patric_dated_390_acc.txt\", header=None, index=None,sep=\"\\n\")\n",
    "# merged_biosamples.to_csv(path + \"merged_biosamples_ncbi_patric_dated_449.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 390 biosample acc into batch entrez (assembly), show 37 without records, extracted accessions from the batch entrez warning\n",
    "# no_asm_biosample_37.txt: copied from warning page\n",
    "\n",
    "with open(path + \"no_asm_biosample_37_acc.txt\",\"w\") as w: # acc without matching assembly record\n",
    "    w.write(\"\")\n",
    "\n",
    "with open(path + \"no_asm_biosample_37.txt\") as f:\n",
    "    file = f.readlines()\n",
    "\n",
    "    for line in file:\n",
    "        acc = line[line.index(\"S\"):line.index(\":\")]\n",
    "        with open(path + \"no_asm_biosample_37_acc.txt\",\"a+\") as w:\n",
    "            w.write(acc + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge no asm record acc with all dated acc\n",
    "\n",
    "no_asm_acc = pd.read_csv(path + \"no_asm_biosample_37_acc.txt\", sep=\"\\n\",header=None)\n",
    "all_acc = pd.read_csv(path + \"ncbi_patric_dated_390_acc.txt\", sep=\"\\n\",header=None)\n",
    "\n",
    "with_asm_acc = pd.DataFrame(set(all_acc[0]).difference(no_asm_acc[0]))\n",
    "# with_asm_acc.to_csv(path + \"with_asm_353_acc.txt\",header=None,sep=\"\\n\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accession of assemblies from NCBI's Assembly database\n",
    "asm_353 = pd.read_csv(path + \"with_asm_353_acc.txt\",header=None)\n",
    "# db downloaded from ncbi assembly db with keyword \"Leptospira\" and filter \"latest\"\n",
    "Lepto_asm_db = ET.parse(path + \"all_Leptospira_asm_db.xml\") # added <root><\\root> to the xml db\n",
    "\n",
    "root = Lepto_asm_db.getroot()\n",
    "\n",
    "with open(path + \"353_asm_accessions.csv\", \"w\") as f: # file to record biosample acc and their corresponding asm acc\n",
    "    f.write(\"\")\n",
    "\n",
    "# write ftp's into a file for download\n",
    "# with open(path + \"353_asm_ftp_GB.txt\", \"w\") as f:\n",
    "#     f.write(\"\")\n",
    "    \n",
    "for record in root.findall(\"DocumentSummary\"): # loop around all asm record in the db\n",
    "    current_biosample = record.find(\"BioSampleAccn\").text \n",
    "\n",
    "    if current_biosample in asm_353[0].values:\n",
    "        asm_acc = record.find(\"Synonym\").find(\"Genbank\").text \n",
    "        # some AssemblyAccession are RefSeq acc, some GB acc, use GB for all of them because Refseq acc missing for some assembly\n",
    "        asm_name = record.find(\"Organism\").text\n",
    "        complete_str = asm_acc + \",\" + asm_name + \",\" + current_biosample  +  \"\\n\"\n",
    "        with open(path + \"353_asm_accessions.csv\", \"a+\") as f:\n",
    "            f.write(complete_str)\n",
    "#         with open(path + \"353_asm_ftp_GB.txt\", \"a+\") as f:\n",
    "#             f.write(record.find(\"FtpPath_GenBank\").text + \"\\n\")  # write Gb format ftp link to the asm into a file\n",
    "\n",
    "# only 351 asm records returned, change file name to 351_asm_accessions.csv  (missing SAMN09220899 and SAMN02947961)\n",
    "# manually added into both ftp file and accession list\n",
    "# use these acc with batch entrez to download all the asm -> batch entrez doesn't work with assembly, use ftp links instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download assemblies on sapelo2\n",
    "# script: download_asm_ftp.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRJNA60435\n",
      "PRJNA167236\n",
      "PRJNA167228\n",
      "PRJNA178716\n",
      "PRJNA167231\n",
      "PRJNA167259\n",
      "PRJNA178717\n",
      "PRJNA167224\n",
      "PRJNA167257\n",
      "PRJNA167254\n",
      "PRJNA167248\n",
      "PRJNA167242\n",
      "PRJNA177156\n",
      "PRJNA177125\n",
      "PRJNA167230\n",
      "PRJNA167252\n",
      "PRJNA167232\n",
      "PRJNA10687\n",
      "PRJNA255705\n",
      "PRJNA255706\n",
      "PRJNA257123\n",
      "PRJNA257123\n",
      "PRJNA264469\n",
      "PRJNA283268\n",
      "PRJNA287300\n",
      "PRJNA287301\n",
      "PRJNA287446\n",
      "PRJNA287446\n",
      "PRJNA291201\n",
      "PRJNA290046\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293092\n",
      "PRJNA293439\n",
      "PRJNA293439\n",
      "PRJNA293439\n",
      "PRJNA293439\n",
      "PRJNA296461\n",
      "PRJNA296461\n",
      "PRJNA296461\n",
      "PRJNA296461\n",
      "PRJNA296461\n",
      "PRJNA296461\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA297523\n",
      "PRJNA298236\n",
      "PRJNA293439\n",
      "PRJNA293092\n",
      "PRJNA301003\n",
      "PRJNA311750\n",
      "PRJNA311750\n",
      "PRJNA311750\n",
      "PRJNA82339\n",
      "PRJNA231221\n",
      "PRJNA360567\n",
      "PRJNA360567\n",
      "PRJNA360567\n",
      "PRJNA360567\n",
      "PRJNA360567\n",
      "PRJNA374548\n",
      "PRJNA374548\n",
      "PRJNA384237\n",
      "PRJNA374022\n",
      "PRJNA374022\n",
      "PRJNA374022\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA395546\n",
      "PRJNA323575\n",
      "PRJNA471857\n",
      "PRJNA471857\n",
      "PRJNA471857\n",
      "PRJNA471857\n",
      "PRJNA477299\n",
      "PRJNA477299\n",
      "PRJNA478605\n",
      "PRJNA478606\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA480513\n",
      "PRJNA528695\n",
      "PRJNA528695\n",
      "PRJNA528695\n",
      "PRJNA543681\n",
      "PRJNA543681\n",
      "PRJNA543681\n",
      "PRJNA543681\n",
      "PRJNA543681\n",
      "PRJNA543681\n",
      "PRJNA560059\n",
      "PRJNA560522\n",
      "PRJNA574874\n",
      "PRJNA574874\n",
      "PRJNA578040\n",
      "PRJNA405969\n",
      "PRJNA405969\n",
      "PRJNA600490\n"
     ]
    }
   ],
   "source": [
    "# metadata for all 389 Leptopsira with assembly dates\n",
    "\n",
    "metadata_db_389 = ET.parse(path + \"dated_biosample_389_metadata.xml\")\n",
    "\n",
    "all_biosample_root= metadata_db_389.getroot()\n",
    "\n",
    "with open(path + \"ncbi_biosample_metadata_389.csv\",\"w\") as f:\n",
    "    headers=\"Collection.Date,La.lon,BioSample.Accession,Host.Name,Geographic.Location,Isolation.Source,Strain,Serovar,Genome.Name,BioProject.Accession,Institute\\n\"\n",
    "    f.write(headers)\n",
    "\n",
    "for biosample in all_biosample_root.findall(\"BioSample\"):\n",
    "    collection_date=\"\"\n",
    "    lat_lon=\"\"\n",
    "    bios_acc = biosample.find(\"Ids\").find(\"Id\").text\n",
    "    name = biosample.find(\"Description\").find(\"Organism\").attrib[\"taxonomy_name\"]\n",
    "    if biosample.find(\"Links\") != None:\n",
    "        if biosample.find(\"Links\").find(\"Link\") != None:\n",
    "            if biosample.find(\"Links\").find(\"Link\").attrib[\"target\"] == \"bioproject\":\n",
    "                project = biosample.find(\"Links\").find(\"Link\").attrib[\"label\"]\n",
    "                print(project)\n",
    "    institute = biosample.find(\"Owner\").find(\"Name\").text\n",
    "    if \",\" in institute:\n",
    "        institute = institute.replace(\",\",\":\")\n",
    "    \n",
    "    for attribute in biosample.find(\"Attributes\").findall(\"Attribute\"):\n",
    "        if attribute.attrib.get(\"display_name\") == \"collection date\":\n",
    "            collection_date = attribute.text\n",
    "        if attribute.attrib.get(\"attribute_name\") == \"lat_lon\":\n",
    "            lat_lon = attribute.text\n",
    "            if \",\" in lat_lon:\n",
    "                lat_lon= lat_lon.replace(\",\",\" \")\n",
    "        if attribute.attrib.get(\"display_name\") == \"host\":\n",
    "            host=attribute.text\n",
    "        if attribute.attrib.get(\"display_name\") == \"geographic location\":\n",
    "            location = attribute.text\n",
    "            if \",\" in location:\n",
    "                location= location.replace(\",\",\" \")\n",
    "        if attribute.attrib.get(\"display_name\") == \"isolation source\":\n",
    "            iso_source = attribute.text\n",
    "            if \",\" in iso_source:\n",
    "                iso_source= iso_source.replace(\",\",\" \")\n",
    "        if attribute.attrib.get(\"display_name\") == \"strain\":\n",
    "            strain = attribute.text\n",
    "        if attribute.attrib.get(\"display_name\") == \"serovar\":\n",
    "            serovar = attribute.text\n",
    "        \n",
    "    complete_str = collection_date + \",\" + lat_lon + \",\" + bios_acc+ \",\"  + host+ \",\"+ location+ \",\"+iso_source+ \",\"+strain+ \",\"+serovar+ \",\"+ name+ \",\"+project+ \",\"+institute + \"\\n\"   \n",
    "    with open(path + \"ncbi_biosample_metadata_389.csv\", \"a+\") as f:\n",
    "            f.write(complete_str)       \n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-6-7a1aa94348c2>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-7a1aa94348c2>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# rename ncbi downloaded assemblies for get_homo/assemblies/*.faa\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# faa_path = \"/scratch/rx32940/get_homo/assemblies/\"\n",
    "\n",
    "# asm_bios = pd.read_csv(\"/scratch/rx32940/get_homo/353_asm_accessions.csv\",header = None)\n",
    "# asm_bios_dict = asm_bios.set_index(0)[1].to_dict()\n",
    "\n",
    "# for faa in os.listdir(faa_path):\n",
    "\n",
    "#     key = faa[:faa.index(\".\")+2]\n",
    "#     if key in asm_bios_dict:\n",
    "#         biosample = asm_bios_dict[key]\n",
    "#         os.rename(faa_path + faa,faa_path + biosample + \".gbff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
