{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path to XML Database\n",
    "  1) search keyword (ex. \"Leptospira\") in BioSample db of NCBI\n",
    "  2) Download XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/Users/rachel/Dropbox/5.Rachel-projects/Phylogeography/Interrogans/\" # Interrogans Path\n",
    "all_lepto_path=\"/Users/rachel/Dropbox/5.Rachel-projects/Phylogeography/SeroAll/\" # all pathogenic leptopsira path (with sero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata for all 389 Leptopsira with assembly dates\n",
    "\n",
    "metadata_db = ET.parse(all_lepto_path + \"ncbi_biosample_db_all.xml\") # search \"Leptospira interrogan\" in NCBI database\n",
    "\n",
    "# write xml into a dataframe\n",
    "\n",
    "with open(all_lepto_path + \"ncbi_biosample_db_all.csv\",\"w\") as f:\n",
    "    headers=\"BioSample.Accession,Bioproject,Collection.Date,La.lon,Host.Name,Geographic.Location,country,Isolation.Source,Strain,Serovar,Genome.Name,Institute\\n\"\n",
    "    f.write(headers)\n",
    "\n",
    "all_biosample_root= metadata_db.getroot()\n",
    "\n",
    "for biosample in all_biosample_root.findall(\"BioSample\"):\n",
    "    # set all variable to empty str to avoid nonotype\n",
    "    bios_acc=\"\"\n",
    "    collection_date=\"\"\n",
    "    lat_lon=\"\"\n",
    "    host=\"\"\n",
    "    location=\"\"\n",
    "    iso_source =\"\"\n",
    "    strain =\"\"\n",
    "    serovar =\"\"\n",
    "    institute=\"\"\n",
    "    country=\"\"\n",
    "    bioproject=\"\"\n",
    "    \n",
    "    bios_acc = biosample.find(\"Ids\").find(\"Id\").text\n",
    "    name = biosample.find(\"Description\").find(\"Title\").text\n",
    "    institute = biosample.find(\"Owner\").find(\"Name\").text\n",
    "    if institute == None:\n",
    "        institute = \"\"\n",
    "    elif \",\" in institute:\n",
    "        institute = institute.replace(\",\",\":\")\n",
    "    \n",
    "    Link= biosample.find(\"Links\")\n",
    "    if Link != None:\n",
    "        for link in Link.findall(\"Link\"):\n",
    "            if link.attrib.get(\"target\") == \"bioproject\":\n",
    "                bioproject=link.attrib.get(\"label\")\n",
    "                \n",
    "    \n",
    "    for attribute in biosample.find(\"Attributes\").findall(\"Attribute\"):\n",
    "        if attribute.attrib.get(\"display_name\") == \"collection date\":\n",
    "            collection_date = attribute.text\n",
    "        if attribute.attrib.get(\"attribute_name\") == \"lat_lon\":\n",
    "            lat_lon = attribute.text\n",
    "            if \",\" in lat_lon:\n",
    "                lat_lon= lat_lon.replace(\",\",\" \")\n",
    "        if attribute.attrib.get(\"display_name\") == \"host\":\n",
    "            host=attribute.text\n",
    "        if attribute.attrib.get(\"display_name\") == \"geographic location\":\n",
    "            location = attribute.text\n",
    "            if \",\" in location:\n",
    "                location= location.replace(\",\",\" \")\n",
    "            if \":\" in location:\n",
    "                country = location.split(\":\")[0] # extract country\n",
    "            else:\n",
    "                country=location\n",
    "        if attribute.attrib.get(\"display_name\") == \"isolation source\":\n",
    "            iso_source = attribute.text\n",
    "            if \",\" in iso_source:\n",
    "                iso_source= iso_source.replace(\",\",\" \")\n",
    "        if attribute.attrib.get(\"display_name\") == \"strain\":\n",
    "            strain = attribute.text\n",
    "        if attribute.attrib.get(\"display_name\") == \"serovar\":\n",
    "            serovar = attribute.text\n",
    "\n",
    "    complete_str =  bios_acc+ \",\"+ bioproject+\",\"  +collection_date + \",\" + lat_lon + \",\" +  host+ \",\"+ location+\",\"+country+ \",\"+iso_source+ \",\"+strain+ \",\"+serovar+ \",\"+ name+ \",\"+institute + \"\\n\"\n",
    "   \n",
    "    with open(all_lepto_path + \"ncbi_biosample_db_all.csv\", \"a+\") as f:\n",
    "        f.write(complete_str) \n",
    "    \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge interrogans isolates with their metadata extracted from XML db above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 12 fields in line 385, saw 13\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea80ba95bb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterrogans_440\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterrogans_440\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"BioSample.Accession\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# read the database we created from last block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minterrogan_db\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"ncbi_biosample_db_all.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2145\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2146\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 385, saw 13\n"
     ]
    }
   ],
   "source": [
    "# # read 440 Leptospira isolates biosample list, coverage and other info \n",
    "# interrogans_440= pd.read_csv(path+\"all_interrogans_440.csv\", index_col=False)\n",
    "# # rename the acc column to match the db, prepare for merging\n",
    "# interrogans_440=interrogans_440.rename(columns = {\"Sample\":\"BioSample.Accession\"}) \n",
    "# # read the database we created from last block\n",
    "# interrogan_db=pd.read_csv(path+\"ncbi_biosample_db_all.csv\")\n",
    "# merge all Leptospira isolates (440) with data frame created above, drop those not in the interrogans list\n",
    "# interrogans_440_2 =interrogans_440.merge(interrogan_db,  how=\"left\",on=\"BioSample.Accession\")\n",
    "# # interrogans_440_2.to_csv(path+\"all_interrogans_metadata_440.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all Pathogenic Leptopsira isolate with their corresponding Metdata in the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the database\n",
    "all_Lepto_db = pd.read_csv(all_lepto_path + \"ncbi_biosample_db_all.csv\")\n",
    "\n",
    "# read in the pathogenic Leptospira isolates NCBI downloaded and self assembled and change column name\n",
    "pathogenic_lepto = pd.read_csv(all_lepto_path + \"ncbiself_assembled_pathogenic_782.csv\").rename(columns={\"Sample\" : \"BioSample.Accession\"})\n",
    "\n",
    "\n",
    "# merge two dataframe\n",
    "pathogenic_lepto_metadata = pathogenic_lepto.merge(all_Lepto_db)\n",
    "\n",
    "# write into file\n",
    "pathogenic_lepto_metadata.to_csv(all_lepto_path + \"ncbiself_metadata_pathogenic_782.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
